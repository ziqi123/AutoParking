0.0001
start
Epoch [1/150], Step [1/1067] Loss: 0.6855, average_loss: 0.6855, learning_rate: 0.0001
Epoch [1/150], Step [11/1067] Loss: 0.1834, average_loss: 0.3280, learning_rate: 0.0001
Epoch [1/150], Step [21/1067] Loss: 0.1485, average_loss: 0.2510, learning_rate: 0.0001
Epoch [1/150], Step [31/1067] Loss: 0.1020, average_loss: 0.2087, learning_rate: 0.0001
Epoch [1/150], Step [41/1067] Loss: 0.0856, average_loss: 0.1824, learning_rate: 0.0001
Epoch [1/150], Step [51/1067] Loss: 0.0712, average_loss: 0.1633, learning_rate: 0.0001
Epoch [1/150], Step [61/1067] Loss: 0.0550, average_loss: 0.1480, learning_rate: 0.0001
Epoch [1/150], Step [71/1067] Loss: 0.0527, average_loss: 0.1356, learning_rate: 0.0001
Epoch [1/150], Step [81/1067] Loss: 0.0440, average_loss: 0.1251, learning_rate: 0.0001
Epoch [1/150], Step [91/1067] Loss: 0.0458, average_loss: 0.1160, learning_rate: 0.0001
Epoch [1/150], Step [101/1067] Loss: 0.0481, average_loss: 0.1082, learning_rate: 0.0001
Epoch [1/150], Step [111/1067] Loss: 0.0320, average_loss: 0.1014, learning_rate: 0.0001
Epoch [1/150], Step [121/1067] Loss: 0.0250, average_loss: 0.0952, learning_rate: 0.0001
Epoch [1/150], Step [131/1067] Loss: 0.0165, average_loss: 0.0896, learning_rate: 0.0001
Epoch [1/150], Step [141/1067] Loss: 0.0196, average_loss: 0.0847, learning_rate: 0.0001
Epoch [1/150], Step [151/1067] Loss: 0.0189, average_loss: 0.0802, learning_rate: 0.0001
Epoch [1/150], Step [161/1067] Loss: 0.0071, average_loss: 0.0760, learning_rate: 0.0001
Epoch [1/150], Step [171/1067] Loss: 0.0198, average_loss: 0.0723, learning_rate: 0.0001
Epoch [1/150], Step [181/1067] Loss: 0.0079, average_loss: 0.0688, learning_rate: 0.0001
Epoch [1/150], Step [191/1067] Loss: 0.0097, average_loss: 0.0657, learning_rate: 0.0001
Epoch [1/150], Step [201/1067] Loss: 0.0077, average_loss: 0.0629, learning_rate: 0.0001
Epoch [1/150], Step [211/1067] Loss: 0.0066, average_loss: 0.0602, learning_rate: 0.0001
Epoch [1/150], Step [221/1067] Loss: 0.0091, average_loss: 0.0578, learning_rate: 0.0001
Epoch [1/150], Step [231/1067] Loss: 0.0086, average_loss: 0.0556, learning_rate: 0.0001
Epoch [1/150], Step [241/1067] Loss: 0.0068, average_loss: 0.0535, learning_rate: 0.0001
Epoch [1/150], Step [251/1067] Loss: 0.0033, average_loss: 0.0516, learning_rate: 0.0001
Epoch [1/150], Step [261/1067] Loss: 0.0048, average_loss: 0.0498, learning_rate: 0.0001
Epoch [1/150], Step [271/1067] Loss: 0.0028, average_loss: 0.0482, learning_rate: 0.0001
Epoch [1/150], Step [281/1067] Loss: 0.0052, average_loss: 0.0466, learning_rate: 0.0001
Epoch [1/150], Step [291/1067] Loss: 0.0040, average_loss: 0.0452, learning_rate: 0.0001
Epoch [1/150], Step [301/1067] Loss: 0.0038, average_loss: 0.0438, learning_rate: 0.0001
Epoch [1/150], Step [311/1067] Loss: 0.0037, average_loss: 0.0425, learning_rate: 0.0001
Epoch [1/150], Step [321/1067] Loss: 0.0031, average_loss: 0.0413, learning_rate: 0.0001
Epoch [1/150], Step [331/1067] Loss: 0.0040, average_loss: 0.0402, learning_rate: 0.0001
Epoch [1/150], Step [341/1067] Loss: 0.0032, average_loss: 0.0391, learning_rate: 0.0001
Epoch [1/150], Step [351/1067] Loss: 0.0058, average_loss: 0.0381, learning_rate: 0.0001
Epoch [1/150], Step [361/1067] Loss: 0.0029, average_loss: 0.0371, learning_rate: 0.0001
Epoch [1/150], Step [371/1067] Loss: 0.0052, average_loss: 0.0362, learning_rate: 0.0001
Epoch [1/150], Step [381/1067] Loss: 0.0028, average_loss: 0.0353, learning_rate: 0.0001
Epoch [1/150], Step [391/1067] Loss: 0.0026, average_loss: 0.0345, learning_rate: 0.0001
Epoch [1/150], Step [401/1067] Loss: 0.0026, average_loss: 0.0337, learning_rate: 0.0001
Epoch [1/150], Step [411/1067] Loss: 0.0031, average_loss: 0.0329, learning_rate: 0.0001
Epoch [1/150], Step [421/1067] Loss: 0.0040, average_loss: 0.0322, learning_rate: 0.0001
Epoch [1/150], Step [431/1067] Loss: 0.0030, average_loss: 0.0316, learning_rate: 0.0001
Epoch [1/150], Step [441/1067] Loss: 0.0015, average_loss: 0.0309, learning_rate: 0.0001
Epoch [1/150], Step [451/1067] Loss: 0.0014, average_loss: 0.0303, learning_rate: 0.0001
Epoch [1/150], Step [461/1067] Loss: 0.0024, average_loss: 0.0297, learning_rate: 0.0001
Epoch [1/150], Step [471/1067] Loss: 0.0012, average_loss: 0.0291, learning_rate: 0.0001
Epoch [1/150], Step [481/1067] Loss: 0.0014, average_loss: 0.0285, learning_rate: 0.0001
Epoch [1/150], Step [491/1067] Loss: 0.0025, average_loss: 0.0280, learning_rate: 0.0001
Epoch [1/150], Step [501/1067] Loss: 0.0013, average_loss: 0.0275, learning_rate: 0.0001
Epoch [1/150], Step [511/1067] Loss: 0.0015, average_loss: 0.0270, learning_rate: 0.0001
Epoch [1/150], Step [521/1067] Loss: 0.0018, average_loss: 0.0265, learning_rate: 0.0001
Epoch [1/150], Step [531/1067] Loss: 0.0013, average_loss: 0.0260, learning_rate: 0.0001
Epoch [1/150], Step [541/1067] Loss: 0.0025, average_loss: 0.0256, learning_rate: 0.0001
Epoch [1/150], Step [551/1067] Loss: 0.0022, average_loss: 0.0252, learning_rate: 0.0001
Epoch [1/150], Step [561/1067] Loss: 0.0009, average_loss: 0.0247, learning_rate: 0.0001
Epoch [1/150], Step [571/1067] Loss: 0.0011, average_loss: 0.0243, learning_rate: 0.0001
Epoch [1/150], Step [581/1067] Loss: 0.0015, average_loss: 0.0239, learning_rate: 0.0001
Epoch [1/150], Step [591/1067] Loss: 0.0008, average_loss: 0.0235, learning_rate: 0.0001
Epoch [1/150], Step [601/1067] Loss: 0.0026, average_loss: 0.0232, learning_rate: 0.0001
Epoch [1/150], Step [611/1067] Loss: 0.0012, average_loss: 0.0228, learning_rate: 0.0001
Epoch [1/150], Step [621/1067] Loss: 0.0010, average_loss: 0.0225, learning_rate: 0.0001
Epoch [1/150], Step [631/1067] Loss: 0.0014, average_loss: 0.0221, learning_rate: 0.0001
Epoch [1/150], Step [641/1067] Loss: 0.0016, average_loss: 0.0218, learning_rate: 0.0001
Epoch [1/150], Step [651/1067] Loss: 0.0014, average_loss: 0.0215, learning_rate: 0.0001
Epoch [1/150], Step [661/1067] Loss: 0.0008, average_loss: 0.0212, learning_rate: 0.0001
Epoch [1/150], Step [671/1067] Loss: 0.0017, average_loss: 0.0209, learning_rate: 0.0001
Epoch [1/150], Step [681/1067] Loss: 0.0008, average_loss: 0.0206, learning_rate: 0.0001
Epoch [1/150], Step [691/1067] Loss: 0.0010, average_loss: 0.0203, learning_rate: 0.0001
Epoch [1/150], Step [701/1067] Loss: 0.0008, average_loss: 0.0201, learning_rate: 0.0001
Epoch [1/150], Step [711/1067] Loss: 0.0013, average_loss: 0.0198, learning_rate: 0.0001
Epoch [1/150], Step [721/1067] Loss: 0.0014, average_loss: 0.0195, learning_rate: 0.0001
Epoch [1/150], Step [731/1067] Loss: 0.0011, average_loss: 0.0193, learning_rate: 0.0001
Epoch [1/150], Step [741/1067] Loss: 0.0010, average_loss: 0.0190, learning_rate: 0.0001
Epoch [1/150], Step [751/1067] Loss: 0.0015, average_loss: 0.0188, learning_rate: 0.0001
Epoch [1/150], Step [761/1067] Loss: 0.0008, average_loss: 0.0186, learning_rate: 0.0001
Epoch [1/150], Step [771/1067] Loss: 0.0011, average_loss: 0.0183, learning_rate: 0.0001
Epoch [1/150], Step [781/1067] Loss: 0.0007, average_loss: 0.0181, learning_rate: 0.0001
Epoch [1/150], Step [791/1067] Loss: 0.0008, average_loss: 0.0179, learning_rate: 0.0001
Epoch [1/150], Step [801/1067] Loss: 0.0007, average_loss: 0.0177, learning_rate: 0.0001
Epoch [1/150], Step [811/1067] Loss: 0.0005, average_loss: 0.0175, learning_rate: 0.0001
Epoch [1/150], Step [821/1067] Loss: 0.0006, average_loss: 0.0173, learning_rate: 0.0001
Epoch [1/150], Step [831/1067] Loss: 0.0007, average_loss: 0.0171, learning_rate: 0.0001
Epoch [1/150], Step [841/1067] Loss: 0.0010, average_loss: 0.0169, learning_rate: 0.0001
Epoch [1/150], Step [851/1067] Loss: 0.0005, average_loss: 0.0167, learning_rate: 0.0001
Epoch [1/150], Step [861/1067] Loss: 0.0008, average_loss: 0.0165, learning_rate: 0.0001
Epoch [1/150], Step [871/1067] Loss: 0.0010, average_loss: 0.0163, learning_rate: 0.0001
Epoch [1/150], Step [881/1067] Loss: 0.0016, average_loss: 0.0162, learning_rate: 0.0001
Epoch [1/150], Step [891/1067] Loss: 0.0007, average_loss: 0.0160, learning_rate: 0.0001
Epoch [1/150], Step [901/1067] Loss: 0.0006, average_loss: 0.0158, learning_rate: 0.0001
Epoch [1/150], Step [911/1067] Loss: 0.0008, average_loss: 0.0156, learning_rate: 0.0001
Epoch [1/150], Step [921/1067] Loss: 0.0009, average_loss: 0.0155, learning_rate: 0.0001
Epoch [1/150], Step [931/1067] Loss: 0.0005, average_loss: 0.0153, learning_rate: 0.0001
Epoch [1/150], Step [941/1067] Loss: 0.0008, average_loss: 0.0152, learning_rate: 0.0001
Epoch [1/150], Step [951/1067] Loss: 0.0007, average_loss: 0.0150, learning_rate: 0.0001
Epoch [1/150], Step [961/1067] Loss: 0.0007, average_loss: 0.0149, learning_rate: 0.0001
Epoch [1/150], Step [971/1067] Loss: 0.0005, average_loss: 0.0147, learning_rate: 0.0001
Epoch [1/150], Step [981/1067] Loss: 0.0005, average_loss: 0.0146, learning_rate: 0.0001
Epoch [1/150], Step [991/1067] Loss: 0.0004, average_loss: 0.0144, learning_rate: 0.0001
Epoch [1/150], Step [1001/1067] Loss: 0.0007, average_loss: 0.0143, learning_rate: 0.0001
Epoch [1/150], Step [1011/1067] Loss: 0.0003, average_loss: 0.0142, learning_rate: 0.0001
Epoch [1/150], Step [1021/1067] Loss: 0.0004, average_loss: 0.0140, learning_rate: 0.0001
Epoch [1/150], Step [1031/1067] Loss: 0.0003, average_loss: 0.0139, learning_rate: 0.0001
Epoch [1/150], Step [1041/1067] Loss: 0.0004, average_loss: 0.0138, learning_rate: 0.0001
Epoch [1/150], Step [1051/1067] Loss: 0.0003, average_loss: 0.0136, learning_rate: 0.0001
Epoch [1/150], Step [1061/1067] Loss: 0.0004, average_loss: 0.0135, learning_rate: 0.0001
Epoch [2/150], Step [1/1067] Loss: 0.0005, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [11/1067] Loss: 0.0006, average_loss: 0.0008, learning_rate: 0.0001
Epoch [2/150], Step [21/1067] Loss: 0.0014, average_loss: 0.0009, learning_rate: 0.0001
Epoch [2/150], Step [31/1067] Loss: 0.0005, average_loss: 0.0008, learning_rate: 0.0001
Epoch [2/150], Step [41/1067] Loss: 0.0006, average_loss: 0.0008, learning_rate: 0.0001
Epoch [2/150], Step [51/1067] Loss: 0.0008, average_loss: 0.0007, learning_rate: 0.0001
Epoch [2/150], Step [61/1067] Loss: 0.0005, average_loss: 0.0007, learning_rate: 0.0001
Epoch [2/150], Step [71/1067] Loss: 0.0004, average_loss: 0.0007, learning_rate: 0.0001
Epoch [2/150], Step [81/1067] Loss: 0.0005, average_loss: 0.0007, learning_rate: 0.0001
Epoch [2/150], Step [91/1067] Loss: 0.0008, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [101/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [111/1067] Loss: 0.0005, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [121/1067] Loss: 0.0004, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [131/1067] Loss: 0.0004, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [141/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [151/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [161/1067] Loss: 0.0004, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [171/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [2/150], Step [181/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [191/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [201/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [211/1067] Loss: 0.0005, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [221/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [231/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [241/1067] Loss: 0.0006, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [251/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [261/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [271/1067] Loss: 0.0005, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [281/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [291/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [301/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [311/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [321/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [331/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [341/1067] Loss: 0.0003, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [361/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [381/1067] Loss: 0.0004, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [2/150], Step [401/1067] Loss: 0.0004, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [411/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [421/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [431/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [441/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [451/1067] Loss: 0.0004, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [461/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [501/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [521/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [531/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [551/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [581/1067] Loss: 0.0004, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [591/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [601/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [611/1067] Loss: 0.0006, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [641/1067] Loss: 0.0006, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [671/1067] Loss: 0.0004, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [691/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [701/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [721/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [731/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [761/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [781/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [801/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [851/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [881/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [891/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [901/1067] Loss: 0.0003, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [921/1067] Loss: 0.0005, average_loss: 0.0004, learning_rate: 0.0001
Epoch [2/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [991/1067] Loss: 0.0003, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1001/1067] Loss: 0.0003, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1051/1067] Loss: 0.0003, average_loss: 0.0003, learning_rate: 0.0001
Epoch [2/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [3/150], Step [1/1067] Loss: 0.0004, average_loss: 0.0004, learning_rate: 0.0001
Epoch [3/150], Step [11/1067] Loss: 0.0025, average_loss: 0.0150, learning_rate: 0.0001
Epoch [3/150], Step [21/1067] Loss: 0.0065, average_loss: 0.0099, learning_rate: 0.0001
Epoch [3/150], Step [31/1067] Loss: 0.0011, average_loss: 0.0077, learning_rate: 0.0001
Epoch [3/150], Step [41/1067] Loss: 0.0009, average_loss: 0.0062, learning_rate: 0.0001
Epoch [3/150], Step [51/1067] Loss: 0.0008, average_loss: 0.0053, learning_rate: 0.0001
Epoch [3/150], Step [61/1067] Loss: 0.0005, average_loss: 0.0046, learning_rate: 0.0001
Epoch [3/150], Step [71/1067] Loss: 0.0004, average_loss: 0.0040, learning_rate: 0.0001
Epoch [3/150], Step [81/1067] Loss: 0.0011, average_loss: 0.0036, learning_rate: 0.0001
Epoch [3/150], Step [91/1067] Loss: 0.0007, average_loss: 0.0033, learning_rate: 0.0001
Epoch [3/150], Step [101/1067] Loss: 0.0004, average_loss: 0.0030, learning_rate: 0.0001
Epoch [3/150], Step [111/1067] Loss: 0.0004, average_loss: 0.0028, learning_rate: 0.0001
Epoch [3/150], Step [121/1067] Loss: 0.0007, average_loss: 0.0026, learning_rate: 0.0001
Epoch [3/150], Step [131/1067] Loss: 0.0005, average_loss: 0.0024, learning_rate: 0.0001
Epoch [3/150], Step [141/1067] Loss: 0.0006, average_loss: 0.0023, learning_rate: 0.0001
Epoch [3/150], Step [151/1067] Loss: 0.0003, average_loss: 0.0022, learning_rate: 0.0001
Epoch [3/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0021, learning_rate: 0.0001
Epoch [3/150], Step [171/1067] Loss: 0.0003, average_loss: 0.0020, learning_rate: 0.0001
Epoch [3/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0019, learning_rate: 0.0001
Epoch [3/150], Step [191/1067] Loss: 0.0003, average_loss: 0.0018, learning_rate: 0.0001
Epoch [3/150], Step [201/1067] Loss: 0.0006, average_loss: 0.0017, learning_rate: 0.0001
Epoch [3/150], Step [211/1067] Loss: 0.0005, average_loss: 0.0017, learning_rate: 0.0001
Epoch [3/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0016, learning_rate: 0.0001
Epoch [3/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0016, learning_rate: 0.0001
Epoch [3/150], Step [241/1067] Loss: 0.0004, average_loss: 0.0015, learning_rate: 0.0001
Epoch [3/150], Step [251/1067] Loss: 0.0003, average_loss: 0.0015, learning_rate: 0.0001
Epoch [3/150], Step [261/1067] Loss: 0.0003, average_loss: 0.0014, learning_rate: 0.0001
Epoch [3/150], Step [271/1067] Loss: 0.0004, average_loss: 0.0014, learning_rate: 0.0001
Epoch [3/150], Step [281/1067] Loss: 0.0005, average_loss: 0.0013, learning_rate: 0.0001
Epoch [3/150], Step [291/1067] Loss: 0.0003, average_loss: 0.0013, learning_rate: 0.0001
Epoch [3/150], Step [301/1067] Loss: 0.0003, average_loss: 0.0013, learning_rate: 0.0001
Epoch [3/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0012, learning_rate: 0.0001
Epoch [3/150], Step [321/1067] Loss: 0.0003, average_loss: 0.0012, learning_rate: 0.0001
Epoch [3/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0012, learning_rate: 0.0001
Epoch [3/150], Step [341/1067] Loss: 0.0003, average_loss: 0.0011, learning_rate: 0.0001
Epoch [3/150], Step [351/1067] Loss: 0.0003, average_loss: 0.0011, learning_rate: 0.0001
Epoch [3/150], Step [361/1067] Loss: 0.0005, average_loss: 0.0011, learning_rate: 0.0001
Epoch [3/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0011, learning_rate: 0.0001
Epoch [3/150], Step [381/1067] Loss: 0.0005, average_loss: 0.0011, learning_rate: 0.0001
Epoch [3/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0010, learning_rate: 0.0001
Epoch [3/150], Step [401/1067] Loss: 0.0003, average_loss: 0.0010, learning_rate: 0.0001
Epoch [3/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0010, learning_rate: 0.0001
Epoch [3/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0010, learning_rate: 0.0001
Epoch [3/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0010, learning_rate: 0.0001
Epoch [3/150], Step [441/1067] Loss: 0.0003, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [461/1067] Loss: 0.0003, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [471/1067] Loss: 0.0003, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [501/1067] Loss: 0.0003, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [511/1067] Loss: 0.0003, average_loss: 0.0009, learning_rate: 0.0001
Epoch [3/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [551/1067] Loss: 0.0003, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [591/1067] Loss: 0.0003, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [601/1067] Loss: 0.0003, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0008, learning_rate: 0.0001
Epoch [3/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [661/1067] Loss: 0.0003, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [741/1067] Loss: 0.0003, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0007, learning_rate: 0.0001
Epoch [3/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [811/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [851/1067] Loss: 0.0004, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [871/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [961/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [971/1067] Loss: 0.0003, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0006, learning_rate: 0.0001
Epoch [3/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [3/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0005, learning_rate: 0.0001
Epoch [4/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [11/1067] Loss: 0.0004, average_loss: 0.0003, learning_rate: 0.0001
Epoch [4/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [61/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [371/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [4/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [31/1067] Loss: 0.0003, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [41/1067] Loss: 0.0003, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [5/150], Step [91/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [231/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [281/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [381/1067] Loss: 0.0003, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [5/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [6/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [7/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [8/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [9/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [10/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [11/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [12/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [13/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [14/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [14/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0003, learning_rate: 0.0001
Epoch [14/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [14/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [15/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [16/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [17/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [18/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [19/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [20/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [21/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [22/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [23/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [24/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [25/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [26/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [27/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [28/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [29/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [30/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [31/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [32/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [33/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [34/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [35/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [36/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [37/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [38/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [39/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [40/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [41/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [42/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [43/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [44/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [45/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [46/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [47/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [48/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [49/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [50/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [51/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [52/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [53/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [54/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [55/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [56/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [57/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [58/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [59/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [60/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [61/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [62/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [63/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [64/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [65/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [66/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [67/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [68/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [69/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [70/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [71/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [72/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [73/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [74/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [75/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [76/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [77/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [78/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [79/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [80/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [81/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [82/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [83/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [84/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [85/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [86/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [87/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [88/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [89/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [90/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [91/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [92/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [93/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [94/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [95/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [96/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [97/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [98/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [99/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [100/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [101/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [102/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [103/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [104/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [105/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [106/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [107/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [108/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [109/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [110/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [111/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [112/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [113/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [114/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [115/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [116/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [117/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [118/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [119/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [120/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [121/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [122/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [123/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [124/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [125/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [126/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [127/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [128/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [129/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [130/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [131/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [132/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [133/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [134/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [135/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [136/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [137/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [138/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [139/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [140/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [141/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [142/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [143/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [144/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [145/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [146/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [147/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [148/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [149/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [11/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [21/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [31/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [41/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [51/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [61/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [71/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [81/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [91/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [101/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [111/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [121/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [131/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [141/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [151/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [161/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [171/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [181/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [191/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [201/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [211/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [221/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [231/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [241/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [251/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [261/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [271/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [281/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [291/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [301/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [311/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [321/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [331/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [341/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [351/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [361/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [371/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [381/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [391/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [401/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [411/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [421/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [431/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [441/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [451/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [461/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [471/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [481/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [491/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [501/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [511/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [521/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [531/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [541/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [551/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [561/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [571/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [581/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [591/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [601/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [611/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [621/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [631/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [641/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [651/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [661/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [671/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [681/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [691/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [701/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [711/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [721/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [731/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [741/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [751/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [761/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [771/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [781/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [791/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [801/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [811/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [821/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [831/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [841/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [851/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [861/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [871/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [881/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [891/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [901/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [911/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [921/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [931/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [941/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [951/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [961/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [971/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [981/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [991/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1001/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1011/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1021/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1031/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1041/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1051/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
Epoch [150/150], Step [1061/1067] Loss: 0.0002, average_loss: 0.0002, learning_rate: 0.0001
